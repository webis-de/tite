optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 5e-5
lr_scheduler:
  class_path: tite.utils.lr_schedulers.ConstantLRSchedulerWithLinearWarmup
  init_args:
    num_warmup_steps: 3000
