model:
  class_path: tite.module.TiteModule
  init_args:
    student:
      class_path: tite.model.TiteModel
      init_args:
        config:
          class_path: tite.model.TiteConfig
          init_args:
            vocab_size: 30522
            num_hidden_layers: 12
            hidden_size:
              - 768
              - 768
              - 768
              - 768
              - 768
              - 768
              - 768
              - 768
              - 768
              - 768
              - 768
              - 768
            num_attention_heads:
              - 12
              - 12
              - 12
              - 12
              - 12
              - 12
              - 12
              - 12
              - 12
              - 12
              - 12
              - 12
            intermediate_size:
              - 3072
              - 3072
              - 3072
              - 3072
              - 3072
              - 3072
              - 3072
              - 3072
              - 3072
              - 3072
              - 3072
              - 3072
            kernel_size:
              - null
              - 3
              - null
              - 3
              - null
              - 3
              - null
              - 3
              - null
              - 3
              - null
              - 3
            stride:
              - null
              - 3
              - null
              - 3
              - null
              - 3
              - null
              - 3
              - null
              - 3
              - null
              - 3
            unpadding: false
    tokenizer:
      class_path: tite.tokenizer.TiteTokenizer
      init_args:
        vocab_file: tokenizers/bert-base-uncased/vocab.txt
        tokenizer_file: tokenizers/bert-base-uncased/tokenizer.json
        do_lower_case: True
        unk_token: '[UNK]'
        sep_token: '[SEP]'
        pad_token: '[PAD]'
        cls_token: '[CLS]'
        mask_token: '[MASK]'
      dict_kwargs:
        model_max_length: 512
    teachers:
    - class_path: tite.teacher.MAETeacher
      init_args:
        padid: 0
    predictors:
    - class_path: tite.predictor.MAEDecoder
      init_args:
        config:
          class_path: tite.bert.BertConfig
          init_args:
            num_hidden_layers: 1
            pooling: false
            unpadding: false
            positional_embedding_type: absolute
        enhanced: true
        mask_prob: 0.5
    losses:
    - class_path: tite.loss.mlm.MLMCrossEntropy
      init_args:
        vocab_size: 30522
    log_additional_metrics: false
    validate_on_glue: true
    validate_on_msmarco: false