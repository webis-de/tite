model:
  class_path: tite.module.TiteModule
  init_args:
    detach_teacher_from_grad: true
    student:
      class_path: tite.bert.BertModel
      init_args:
        config:
          class_path: tite.bert.BertConfig
          init_args:
            num_hidden_layers: 12
    tokenizer:
      class_path: tite.tokenizer.TiteTokenizer
      init_args:
        vocab_file: tokenizers/bert-base-uncased/vocab.txt
        tokenizer_file: tokenizers/bert-base-uncased/tokenizer.json
        do_lower_case: True
        unk_token: '[UNK]'
        sep_token: '[SEP]'
        pad_token: '[PAD]'
        cls_token: '[CLS]'
        mask_token: '[MASK]'
      dict_kwargs:
        model_max_length: 512
    transformations:
      - class_path: tite.transformations.MLMMaskTokens
        init_args:
          vocab_size: 30522
          maskid: 103
          clsid: 101
          sepid: 102
          mask_prob: 0.3
    predictor:
      class_path: tite.predictor.Identity
    loss:
      class_path: tite.loss.ProjectedBarlowTwins
      init_args:
        lmbda: 0.005
        embeddim: 768
        sizes: [8192, 8192, 8192]
    max_length: 256