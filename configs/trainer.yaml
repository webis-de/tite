# lightning.pytorch==2.2.0.post0
seed_everything: 42
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: bf16-mixed
  logger:
    class_path: CustomWandbLogger
    init_args:
      project: tite
    dict_kwargs:
      entity: tite
  callbacks:
    - class_path: ModelCheckpoint
      init_args:
        save_on_train_epoch_end: false
        save_top_k: -1
  max_steps: 70000
  val_check_interval: 32000
  accumulate_grad_batches: 32
  gradient_clip_val: 10
  detect_anomaly: false
  inference_mode: false